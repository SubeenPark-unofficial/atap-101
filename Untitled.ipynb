{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngram Language Models \n",
    "## Backgrounds\n",
    "-----\n",
    "### Significant Collocations\n",
    "#### nltk에서 significant collocations를 찾기 위해 사용하는 도구들\n",
    "* `CollocationFinder` :  collect collocation candidate frequencies, filter and rank them\n",
    "* `NgramAssocMeasuers`: generic association measures. Each public method returns a score.(Available methods : chi squre, jaccard, liklihood_ratio, mi_like, pmi, poisson_stirling, raw_freq, student_t...)\n",
    "\n",
    "#### `rank_quadgrams`\n",
    "* `ngrams = QuadgramCollocationFinder.from_words(corpus.words())`\n",
    "\t* `corpus.words()` -> corpus 내부의 Text가 word tokenization이 끝난 형태로 return\n",
    "    * `from_words`: `QuadgramCollocationFinder` class 내부의 함수. Construct a QuadgramCollocationFinder for n-grams(n<4) in the given sequence. \n",
    "    * `scored = ngrams.score_ngrams(metric)` : `metric`은 `QuadgramAssocMeasures`에서 제공하는 방법 중 하나. `metric`을 기준으로 더 중요한 ngram이 무엇인지 저장되어 `scored`에 저장된다. \n",
    "    \n",
    "``` \n",
    "# Full code\n",
    "def rank_quadgrams(corpus, metric, path=None):\n",
    "    \"\"\"\n",
    "    Find and rank quadgrams from the supplied corpus using the given\n",
    "    association metric. Write the quadgrams out to the given path if\n",
    "    supplied otherwise return the list in memory.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a collocation ranking utility from corpus words.\n",
    "    ngrams = QuadgramCollocationFinder.from_words(corpus.words())\n",
    "\n",
    "    # Rank collocations by an association metric\n",
    "    scored = ngrams.score_ngrams(metric)\n",
    "\n",
    "    if path:\n",
    "        with open(path, 'w') as f:\n",
    "            f.write(\"Collocation\\tScore ({})\\n\".format(metric.__name__))\n",
    "            for ngram, score in scored:\n",
    "                f.write(\"{}\\t{}\\n\".format(repr(ngram), score))\n",
    "    else:\n",
    "        return scored\n",
    "```\n",
    "따라서 \n",
    "```\n",
    "rank_quadgrams(\n",
    "        corpus, QuadgramAssocMeasures.likelihood_ratio, \"quadgrams.txt\"\n",
    "    )\n",
    "```\n",
    "와 같이 함수를 실행시키면 corpus의 quadgram들이 liklihood_ratio를 기준으로 정렬된 후 \"quadgrams.txt\" 파일에 순위 순으로 저장된다. \n",
    "\n",
    "\n",
    "#### `SignificantCollocations`\n",
    "* `BaseEstimator, TransformerMixin` : `sklearn` 라이브러리의 기본 클래스. preprocessing 과정에서 pipeline을 커스텀하기 위하여 사용한다. (참고: [BaseEstimator in sklearn.base](https://stackoverflow.com/questions/15233632/baseestimator-in-sklearn-base-python), [SCIKIT LEARN 전처리를 위한 변환기 만들기](https://databuzz-team.github.io/2018/11/11/make_pipeline/)\n",
    "* `def fit(self, docs, target)` : 문서 형태의 `docs`를 input으로 받아 ngram들을 형성하고 `ngrams`에 저장한다. 그리고 `self._scored_`에 `self.metric`을 기준으로 정렬된 significant collocations(ngrams)를 `dict` 형태로 저장한다. \n",
    "* `def transformation(self, docs, target)` : raw_freq가 높은 상위 50개의 ngram에 대하여 ngram과 그 score(fit method 에서 구한 점수)를 dict 형태로 저장한다.\n",
    "\n",
    "## Ngram Language Model\n",
    "-----\n",
    "### NgramCounter\n",
    "```\n",
    "class NgramCounter(object):\n",
    "    \"\"\"\n",
    "    The NgramCounter class counts ngrams given a vocabulary and ngram size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n, vocabulary, unknown=\"<UNK>\"):\n",
    "        \"\"\"\n",
    "        n is the size of the ngram\n",
    "        \"\"\"\n",
    "        if n < 1:\n",
    "            raise ValueError(\"ngram size must be greater than or equal to 1\")\n",
    "\n",
    "        self.n = n\n",
    "        self.unknown = unknown\n",
    "        self.padding = {\n",
    "            \"pad_left\": True,\n",
    "            \"pad_right\": True,\n",
    "            \"left_pad_symbol\": \"<s>\",\n",
    "            \"right_pad_symbol\": \"</s>\"\n",
    "        }\n",
    "\n",
    "        self.vocabulary = vocabulary\n",
    "        self.allgrams = defaultdict(ConditionalFreqDist)\n",
    "        self.ngrams = FreqDist()\n",
    "        self.unigrams = FreqDist()\n",
    "\n",
    "    def train_counts(self, training_text):\n",
    "        for sent in training_text:\n",
    "            checked_sent = (self.check_against_vocab(word) for word in sent)\n",
    "            sent_start = True\n",
    "            for ngram in self.to_ngrams(checked_sent):\n",
    "                self.ngrams[ngram] += 1\n",
    "                context, word = tuple(ngram[:-1]), ngram[-1]\n",
    "                if sent_start:\n",
    "                    for context_word in context:\n",
    "                        self.unigrams[context_word] += 1\n",
    "                    sent_start = False\n",
    "\n",
    "                for window, ngram_order in enumerate(range(self.n, 1, -1)):\n",
    "                    context = context[window:]\n",
    "                    self.allgrams[ngram_order][context][word] += 1\n",
    "                self.unigrams[word] += 1\n",
    "\n",
    "    def check_against_vocab(self, word):\n",
    "        if word in self.vocabulary:\n",
    "            return word\n",
    "        return self.unknown\n",
    "\n",
    "    def to_ngrams(self, sequence):\n",
    "        \"\"\"\n",
    "        Wrapper for NLTK ngrams method\n",
    "        \"\"\"\n",
    "        return ngrams(sequence, self.n, **self.padding)\n",
    "```\n",
    "*  `def __init__(self, n, vocabulary, unknown=\"<UNK>\")`\n",
    "\n",
    "\n",
    "   \n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
